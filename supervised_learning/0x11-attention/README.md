<ul>
<li>What is the attention mechanism?</li>
<li>How to apply attention to RNNs</li>
<li>What is a transformer?</li>
<li>How to create an encoder-decoder transformer model</li>
<li>What is GPT? </li>
<li>What is BERT?</li>
<li>What is self-supervised learning?</li>
<li>How to use BERT for specific NLP tasks</li>
<li>What is SQuAD? GLUE?</li>
</ul>